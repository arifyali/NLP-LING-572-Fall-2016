{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/arifali/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys, os, glob\n",
    "\n",
    "from collections import Counter\n",
    "from math import log\n",
    "from numpy import mean\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "from evaluation import Eval\n",
    "\n",
    "from nbmodel import load_docs\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_feats(doc):\n",
    "    \"\"\"\n",
    "    Extract input features (percepts) for a given document.\n",
    "    Each percept is a pairing of a name and a boolean, integer, or float value.\n",
    "    A document's percepts are the same regardless of the label considered.\n",
    "    \"\"\"\n",
    "    ff = Counter()\n",
    "    for word in doc:\n",
    "        ff[word] = 1\n",
    "    ff['bias_term'] = 1\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_featurized_docs(datasplit):\n",
    "    rawdocs, labels = load_docs(datasplit, lemmatize=False)\n",
    "    assert len(rawdocs)==len(labels)>0,datasplit\n",
    "    featdocs = []\n",
    "    for d in rawdocs:\n",
    "        featdocs.append(extract_feats(d))\n",
    "    return featdocs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CLASSES = ['ARA', 'DEU', 'FRA', 'HIN', 'ITA', 'JPN', 'KOR', 'SPA', 'TEL', 'TUR', 'ZHO']\n",
    "MAX_ITERATIONS = 10\n",
    "dev_docs,  dev_labels  = load_featurized_docs('dev')\n",
    "weights = {l: Counter() for l in CLASSES}\n",
    "#learn(train_docs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_docs, train_labels = load_featurized_docs('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CLASSES = ['ARA', 'DEU', 'FRA', 'HIN', 'ITA', 'JPN', 'KOR', 'SPA', 'TEL', 'TUR', 'ZHO']\n",
    "MAX_ITERATIONS = MAX_ITERATIONS\n",
    "dev_docs = dev_docs\n",
    "dev_labels = dev_labels\n",
    "weights = {l: Counter() for l in CLASSES}\n",
    "\n",
    "def score(doc, label):\n",
    "    \"\"\"\n",
    "    Returns the current model's score of labeling the given document\n",
    "    with the given label.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    for word in doc:\n",
    "        score += weights[label][word]*doc[word]\n",
    "    return score\n",
    "\n",
    "def predict(doc):\n",
    "    \"\"\"\n",
    "    Return the highest-scoring label for the document under the current model.\n",
    "    \"\"\"\n",
    "    max_label = CLASSES[0]\n",
    "    max_score = score(doc, max_label)\n",
    "    # note: the dict method from nbmodels don't work because there is a greater certainity of \n",
    "    for l in CLASSES[1:]:\n",
    "        current_score = score(doc, l)\n",
    "        if current_score > max_score:\n",
    "            max_score = current_score\n",
    "            max_label = l\n",
    "    return max_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_docs,  dev_labels  = load_featurized_docs('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max weights for ARA: ['alot', 'statment', 'thier', 'self', 'any', 'its', 'right', 'i', 'Also', 'Finally']\n",
      "min weights for ARA: ['If', 'out', 'difficult', 'lot', 'little', 'statement', 'why', 'already', 'various', 'everybody']\n",
      "bias term for ARA: 6\n",
      "max weights for DEU: ['statement', 'often', 'opinion', 'on', 'beeing', 'next', 'why', 'faster', 'you', 'special']\n",
      "min weights for DEU: [\"'s\", 'we', 'i', 'However', 'person', 'those', ';', 'by', 'find', 'forget']\n",
      "bias term for DEU: -6\n",
      "max weights for FRA: ['Indeed', '...', 'fact', 'instance', 'It', 'exemple', 'France', 'question', 'contrary', 'society']\n",
      "min weights for FRA: ['from', 'get', 'above', 'agree', 'public', 'reach', 'with', 'us', 'information', 'makes']\n",
      "bias term for FRA: 1\n",
      "max weights for HIN: ['then', 'towards', 'which', 'has', 'its', 'i', 'So', 'particular', 'u', 'upon']\n",
      "min weights for HIN: ['Finally', 'who', 'years', 'reasons', 'others', 'I', 'other', 'success', 'probably', 'instance']\n",
      "bias term for HIN: 1\n",
      "max weights for ITA: [':', 'think', 'experience', 'an', 'lot', 'useful', 'problem', 'important', 'probably', \"n't\"]\n",
      "min weights for ITA: ['get', 'However', 'But', 'hard', 'may', 'By', 'Many', 'than', '?', 'There']\n",
      "bias term for ITA: -3\n",
      "max weights for JPN: ['Japan', 'tend', 'disagree', 'Japanese', 'reasons', 'Therefore', 'If', 'using', 'each', 'might']\n",
      "min weights for JPN: ['an', 'he', 'every', 'will', 'a', 'all', 'i', 'money', 'time', 'People']\n",
      "bias term for JPN: 5\n",
      "max weights for KOR: ['However', 'Korea', 'Even', 'First', 'lots', 'just', 'company', 'Second', 'Most', 'study']\n",
      "min weights for KOR: ['today', 'big', 'consider', 'hand', 'this', 'always', 'able', 'ask', 'take', 'end']\n",
      "bias term for KOR: 0\n",
      "max weights for SPA: ['risk', 'maybe', 'going', 'enviroment', 'activities', 'future', 'diferent', 'public', 'city', 'matter']\n",
      "min weights for SPA: ['which', 'So', 'i', 'First', 'from', 'often', 'on', 'many', 'right', 'useful']\n",
      "bias term for SPA: -2\n",
      "max weights for TEL: ['statement', 'by', 'i', 'some', 'cannot', 'out', 'days', 'may', 'we', 'etc']\n",
      "min weights for TEL: ['just', ';', 'or', 'live', 'However', 'you', 'fact', ':', 'believe', 'First']\n",
      "bias term for TEL: 4\n",
      "max weights for TUR: ['Because', 'Turkey', 'being', 'life', 'sum', 'be', 'university', 'last', 'must', 'trying']\n",
      "min weights for TUR: ['statement', 'often', 'feel', 'experience', 'lot', ',', 'Second', 'I', 'another', 'been']\n",
      "bias term for TUR: -2\n",
      "max weights for ZHO: ['still', 'Take', 'China', 'Because', 'may', 'just', 'air', 'far', 'also', 'People']\n",
      "min weights for ZHO: ['able', 'having', 'difficult', 'had', ':', 'expensive', 'with', 'its', 'Also', 'move']\n",
      "bias term for ZHO: -4\n",
      "max weights for ARA: ['alot', 'statment', 'self', 'its', 'will', 'thier', 'fun', 'Finally', 'any', 'cause']\n",
      "min weights for ARA: ['statement', 'lot', 'If', 'We', 'just', 'difficult', 'everybody', 'can', 'come', 'knowledge']\n",
      "bias term for ARA: 6\n",
      "max weights for DEU: ['often', 'opinion', 'statement', 'on', 'beeing', 'But', 'you', 'negative', 'special', 'Furthermore']\n",
      "min weights for DEU: ['we', \"'s\", 'main', 'However', 'can', ';', 'making', 'i', 'may', 'having']\n",
      "bias term for DEU: -8\n",
      "max weights for FRA: ['...', 'Indeed', 'fact', 'thinking', 'during', 'instance', 'exemple', 'France', 'evolution', 'an']\n",
      "min weights for FRA: ['above', 'human', 'There', 'times', 'reasons', 'agree', 'from', 'If', 'many', 'study']\n",
      "bias term for FRA: 0\n",
      "max weights for HIN: ['towards', 'then', 'particular', 'which', 'well', 'Now', 'its', 'upon', 'according', 'enjoyment']\n",
      "min weights for HIN: ['Finally', 'think', 'years', 'others', 'Because', 'did', 'jobs', 'find', 'probably', 'Although']\n",
      "bias term for HIN: 0\n",
      "max weights for ITA: [':', 'think', 'experience', 'fact', 'probably', 'real', 'Infact', 'lot', 'important', 'able']\n",
      "min weights for ITA: ['get', 'may', 'However', 'hard', 'By', 'over', 'Also', 'First', 'Many', 'There']\n",
      "bias term for ITA: -2\n",
      "max weights for JPN: ['Japan', 'If', 'disagree', 'tend', 'Therefore', 'deeply', 'Japanese', 'However', 'study', 'however']\n",
      "min weights for JPN: ['an', 'he', 'a', 'giving', 'All', 'possible', 'every', 'its', 'my', 'times']\n",
      "bias term for JPN: 8\n",
      "max weights for KOR: ['However', 'Korea', 'Most', 'lots', \"'s\", 'just', 'various', 'study', '`', 'Second']\n",
      "min weights for KOR: ['this', 'end', 'big', 'for', 'ask', 'them', 'consider', 'today', 'each', 'risk']\n",
      "bias term for KOR: -3\n",
      "max weights for SPA: ['maybe', 'diferent', 'enviroment', 'activities', 'going', 'transport', 'moment', 'lifes', 'risk', 'tell']\n",
      "min weights for SPA: ['which', 'from', 'successful', 'useful', 'So', 'i', 'often', 'According', 'become', 'on']\n",
      "bias term for SPA: -2\n",
      "max weights for TEL: ['statement', 'by', 'i', 'days', 'any', 'may', 'above', 'cannot', 'ideas', 'should']\n",
      "min weights for TEL: [';', 'or', 'two', 'However', 'just', 'believe', 'live', ':', 'Therefore', 'point']\n",
      "bias term for TEL: 5\n",
      "max weights for TUR: ['Turkey', 'Because', 'ways', 'being', 'create', 'second', 'dont', 'chance', 'sum', 'according']\n",
      "min weights for TUR: ['often', 'usually', 'out', 'might', 'experience', 'cases', 'feel', 'Second', ',', 'society']\n",
      "bias term for TUR: 1\n",
      "max weights for ZHO: ['still', 'just', 'Take', 'China', 'With', 'above', 'air', 'need', 'lives', 'exciting']\n",
      "min weights for ZHO: ['able', 'move', 'its', 'difficult', 'Also', 'sure', 'order', 'days', 'explain', 'situations']\n",
      "bias term for ZHO: -5\n",
      "max weights for ARA: ['alot', 'statment', 'fun', 'depend', 'any', 'thier', 'its', 'Also', 'self', 'lives']\n",
      "min weights for ARA: ['lot', 'If', 'up', 'statement', 'just', 'little', 'knowledge', 'We', 'difficult', 'possible']\n",
      "bias term for ARA: 6\n",
      "max weights for DEU: ['opinion', 'often', 'beeing', 'special', 'statement', 'on', 'negative', 'Furthermore', 'But', 'money']\n",
      "min weights for DEU: [\"'s\", 'person', 'we', 'However', 'main', 'thing', ';', 'easily', 'may', 'making']\n",
      "bias term for DEU: -9\n",
      "max weights for FRA: ['Indeed', '...', 'fact', 'exemple', 'conclude', 'instance', 'thinking', 'contrary', 'population', 'France']\n",
      "min weights for FRA: ['above', 'There', 'hard', 'times', 'information', 'traffic', 'agree', 'us', 'human', 'future']\n",
      "bias term for FRA: 0\n",
      "max weights for HIN: ['towards', 'then', 'well', 'particular', 'which', 'Now', 'number', 'u', 'has', 'India']\n",
      "min weights for HIN: ['Finally', 'years', 'jobs', 'probably', 'others', 'reasons', 'Although', 'bought', 'hard', 'find']\n",
      "bias term for HIN: 1\n",
      "max weights for ITA: [':', 'think', 'possibility', 'probably', '!', 'useful', 'Infact', 'fact', 'organize', 'important']\n",
      "min weights for ITA: ['get', 'may', 'First', 'However', 'Also', 'Many', '?', 'over', 'By', 'learn']\n",
      "bias term for ITA: -2\n",
      "max weights for JPN: ['Japan', 'If', 'tend', 'Japanese', 'However', 'Therefore', 'reasons', 'especially', 'using', 'though']\n",
      "min weights for JPN: ['an', 'a', 'he', 'i', 'every', 'will', 'between', 'sum', 'possible', 'places']\n",
      "bias term for JPN: 8\n",
      "max weights for KOR: ['However', 'Korea', 'lots', 'various', 'Most', 'Second', 'usually', 'Even', 'company', 'First']\n",
      "min weights for KOR: ['ask', 'end', 'this', 'take', 'on', 'how', 'consider', 'big', 'for', 'hand']\n",
      "bias term for KOR: -1\n",
      "max weights for SPA: ['maybe', 'activities', 'diferent', 'transport', 'going', 'differents', 'goals', 'matter', 'enviroment', 'just']\n",
      "min weights for SPA: ['which', 'So', 'from', 'useful', 'successful', 'on', 'i', 'First', 'might', 'According']\n",
      "bias term for SPA: -2\n",
      "max weights for TEL: ['i', 'may', 'by', 'days', 'statement', 'ideas', 'Finally', 'some', 'spending', \"''\"]\n",
      "min weights for TEL: ['just', 'However', ';', 'believe', 'you', 'or', 'two', 'live', 'Therefore', 'experience']\n",
      "bias term for TEL: 4\n",
      "max weights for TUR: ['Turkey', 'Because', 'being', 'dont', 'create', 'chance', 'university', 'sum', 'according', 'ways']\n",
      "min weights for TUR: ['often', 'society', 'might', 'feel', 'cases', 'study', 'usually', 'Second', ',', 'care']\n",
      "bias term for TUR: 1\n",
      "max weights for ZHO: ['just', 'Take', 'still', 'China', 'may', 'With', 'ability', 'air', 'Only', 'how']\n",
      "min weights for ZHO: ['able', 'move', 'its', 'sure', 'explain', 'Also', 'having', 'with', 'difficult', 'changed']\n",
      "bias term for ZHO: -6\n",
      "max weights for ARA: ['alot', 'statment', 'fun', 'depend', 'thier', 'will', 'self', 'lives', 'major', 'customers']\n",
      "min weights for ARA: ['statement', 'little', 'lot', 'If', 'often', 'want', 'Firstly', 'difficult', 'probably', 'We']\n",
      "bias term for ARA: 7\n",
      "max weights for DEU: ['opinion', 'often', 'statement', 'beeing', '-', 'money', 'special', 'But', 'next', 'out']\n",
      "min weights for DEU: [\"'s\", 'we', 'person', 'However', ';', 'lots', 'main', 'thing', 'easily', 'each']\n",
      "bias term for DEU: -9\n",
      "max weights for FRA: ['Indeed', '...', 'exemple', 'conclude', 'population', 'evolution', 'will', 'thinking', 'why', 'France']\n",
      "min weights for FRA: ['above', 'hard', 'us', 'human', 'out', '``', 'There', 'traffic', 'aspects', 'university']\n",
      "bias term for FRA: -1\n",
      "max weights for HIN: ['towards', 'then', 'topic', 'Now', 'dont', 'particular', 'which', 'todays', 'according', 'field']\n",
      "min weights for HIN: ['years', 'Finally', 'reasons', 'jobs', 'people', 'probably', 'maybe', 'nowadays', 'think', 'bought']\n",
      "bias term for HIN: 1\n",
      "max weights for ITA: [':', 'think', 'possibility', 'probably', '!', 'useful', 'experience', 'fact', 'an', 'organize']\n",
      "min weights for ITA: ['get', 'There', 'However', 'may', 'Also', 'Many', '?', 'over', 'First', 'People']\n",
      "bias term for ITA: -2\n",
      "max weights for JPN: ['Japan', 'tend', 'If', 'Japanese', 'Therefore', 'However', 'There', 'each', 'disagree', 'however']\n",
      "min weights for JPN: ['every', 'an', 'he', 'last', 'a', 'i', 'field', 'times', 'sum', 'possible']\n",
      "bias term for JPN: 8\n",
      "max weights for KOR: ['Korea', 'However', 'Even', 'lots', 'various', 'study', \"n't\", 'As', 'usually', 'Most']\n",
      "min weights for KOR: ['ask', 'this', 'end', 'take', 'for', 'on', 'hand', 'completely', 'always', 'good']\n",
      "bias term for KOR: -1\n",
      "max weights for SPA: ['maybe', 'going', 'diferent', 'transport', 'activities', 'moment', 'probably', 'hand', 'differents', 'matter']\n",
      "min weights for SPA: ['which', 'i', 'So', 'from', 'successful', 'useful', 'often', 'become', 'on', 'especially']\n",
      "bias term for SPA: -2\n",
      "max weights for TEL: ['i', 'may', 'by', 'statement', 'cannot', 'conclude', 'days', 'some', 'above', 'any']\n",
      "min weights for TEL: ['believe', 'just', 'or', 'However', ';', 'you', 'live', 'two', ':', 'Therefore']\n",
      "bias term for TEL: 6\n",
      "max weights for TUR: ['Turkey', 'Because', 'being', 'dont', 'create', 'chance', 'sum', 'traffic', 'university', 'done']\n",
      "min weights for TUR: ['often', 'society', ',', 'might', 'will', 'Second', 'feel', 'what', 'lot', 'experience']\n",
      "bias term for TUR: -1\n",
      "max weights for ZHO: ['Take', 'still', 'China', 'kinds', 'just', 'With', 'may', 'let', 'nowadays', 'gain']\n",
      "min weights for ZHO: ['able', 'move', 'explain', 'sure', 'having', 'its', 'difficult', 'number', 'this', 'fact']\n",
      "bias term for ZHO: -6\n",
      "max weights for ARA: ['alot', 'depend', 'thier', 'statment', 'will', 'self', 'customers', 'Also', 'advertisments', 'addition']\n",
      "min weights for ARA: ['statement', 'little', 'knowledge', 'lot', 'If', 'difficult', 'often', 'possible', 'purpose', 'seems']\n",
      "bias term for ARA: 6\n",
      "max weights for DEU: ['often', 'opinion', 'statement', 'beeing', 'special', 'money', 'negative', '-', 'flexible', 'Furthermore']\n",
      "min weights for DEU: [\"'s\", 'we', ';', 'However', 'each', 'making', 'person', 'having', 'lots', 'may']\n",
      "bias term for DEU: -9\n",
      "max weights for FRA: ['Indeed', '...', 'exemple', 'population', 'why', 'evolution', 'conclude', 'aim', 'France', 'fact']\n",
      "min weights for FRA: ['above', 'There', 'human', 'traffic', 'hard', 'out', '``', 'problems', 'aspects', 'university']\n",
      "bias term for FRA: 0\n",
      "max weights for HIN: ['towards', 'then', 'which', 'topic', 'particular', 'todays', 'Now', 'dont', 'according', 'So']\n",
      "min weights for HIN: ['Finally', 'years', 'reasons', 'jobs', 'others', 'nowadays', 'people', 'when', 'probably', 'Although']\n",
      "bias term for HIN: 0\n",
      "max weights for ITA: [':', 'think', 'possibility', 'fact', 'useful', 'organize', 'important', 'Infact', ')', 'probably']\n",
      "min weights for ITA: ['get', 'may', 'First', 'over', 'Also', 'There', 'As', 'However', 'Many', '?']\n",
      "bias term for ITA: -2\n",
      "max weights for JPN: ['Japan', 'If', 'Japanese', 'disagree', 'tend', 'First', 'especially', 'There', 'each', 'style']\n",
      "min weights for JPN: ['an', 'every', 'will', 'he', 'last', 'sum', 'a', 'People', 'bad', 'i']\n",
      "bias term for JPN: 9\n",
      "max weights for KOR: ['Korea', 'However', 'lots', 'various', 'Even', 'study', 'As', 'usually', 'Second', 'famous']\n",
      "min weights for KOR: ['for', 'come', 'ask', 'take', 'completely', 'hand', 'this', 'end', 'today', 'become']\n",
      "bias term for KOR: 1\n",
      "max weights for SPA: ['activities', 'going', 'moment', 'maybe', 'diferent', 'transport', 'hand', 'goals', 'enviroment', 'probably']\n",
      "min weights for SPA: ['which', 'So', 'successful', 'useful', 'i', 'especially', 'from', 'often', 'First', 'might']\n",
      "bias term for SPA: -3\n",
      "max weights for TEL: ['i', 'may', 'cannot', 'by', 'days', 'Finally', 'statement', 'conclude', 'some', 'he']\n",
      "min weights for TEL: ['believe', 'However', ';', 'or', 'just', 'you', 'two', 'live', 'Therefore', 'kind']\n",
      "bias term for TEL: 5\n",
      "max weights for TUR: ['Turkey', 'Because', 'being', 'dont', 'create', 'ways', 'succesful', 'chance', 'sum', 'traffic']\n",
      "min weights for TUR: ['society', 'often', 'experience', ',', 'will', 'Second', 'cases', 'keep', 'few', 'might']\n",
      "bias term for TUR: 0\n",
      "max weights for ZHO: ['still', 'Take', 'China', 'just', 'kinds', 'three', 'With', 'let', 'ability', '?']\n",
      "min weights for ZHO: ['able', 'move', 'having', 'Also', 'explain', 'with', 'its', 'fact', 'difficult', 'sure']\n",
      "bias term for ZHO: -7\n",
      "max weights for ARA: ['alot', 'thier', 'will', 'depend', 'statment', 'self', 'transportation', 'customers', 'needs', 'cause']\n",
      "min weights for ARA: ['statement', 'lot', 'little', 'possible', 'purpose', 'knowledge', 'seems', 'has', 'already', 'difficult']\n",
      "bias term for ARA: 7\n",
      "max weights for DEU: ['often', 'opinion', 'statement', 'beeing', 'special', '-', 'negative', 'flexible', 'Furthermore', 'But']\n",
      "min weights for DEU: ['we', \"'s\", ';', 'However', 'may', 'making', 'person', 'i', 'each', 'main']\n",
      "bias term for DEU: -10\n",
      "max weights for FRA: ['Indeed', '...', 'population', 'exemple', 'instance', 'evolution', 'France', 'fact', 'show', ':']\n",
      "min weights for FRA: ['above', 'There', 'hard', 'human', 'agree', 'problems', 'out', 'places', 'traffic', 'aspects']\n",
      "bias term for FRA: -2\n",
      "max weights for HIN: ['towards', 'then', 'particular', 'which', 'todays', 'Now', 'So', 'dont', 'well', 'according']\n",
      "min weights for HIN: ['Finally', 'years', 'nowadays', 'others', 'people', 'reasons', 'jobs', 'probably', 'bought', 'when']\n",
      "bias term for HIN: 0\n",
      "max weights for ITA: ['think', ':', 'possibility', 'fact', 'organize', 'probably', 'Infact', 'useful', 'important', 'kind']\n",
      "min weights for ITA: ['get', 'As', 'over', 'There', 'First', 'may', 'Also', 'People', 'However', 'tour']\n",
      "bias term for ITA: -2\n",
      "max weights for JPN: ['Japan', 'Japanese', 'However', 'If', 'Therefore', 'tend', 'each', 'First', 'disagree', 'however']\n",
      "min weights for JPN: ['every', 'an', 'last', 'sum', 'will', 'People', 'he', 'a', 'i', 'possible']\n",
      "bias term for JPN: 8\n",
      "max weights for KOR: ['Korea', 'However', 'lots', 'various', 'Second', 'study', 'comfortable', 'usually', 'Even', 'just']\n",
      "min weights for KOR: ['for', 'ask', 'take', 'hand', 'come', 'completely', 'this', 'maybe', 'else', 'become']\n",
      "bias term for KOR: 1\n",
      "max weights for SPA: ['going', 'activities', 'transport', 'maybe', 'diferent', 'matter', 'goals', 'differents', 'lifes', 'enviroment']\n",
      "min weights for SPA: ['which', 'successful', 'from', 'i', 'useful', 'So', 'might', 'especially', 'on', 'often']\n",
      "bias term for SPA: -2\n",
      "max weights for TEL: ['i', 'by', 'may', 'cannot', 'days', 'he', 'statement', 'spending', 'some', 'any']\n",
      "min weights for TEL: ['believe', 'However', ';', 'just', 'or', 'you', 'live', 'Therefore', 'two', 'kind']\n",
      "bias term for TEL: 5\n",
      "max weights for TUR: ['Turkey', 'Because', 'being', 'succesful', 'dont', 'chance', 'traffic', 'ways', 'related', 'sum']\n",
      "min weights for TUR: ['society', 'often', 'experience', 'Second', ',', 'keep', 'various', 'cases', 'might', 'few']\n",
      "bias term for TUR: 2\n",
      "max weights for ZHO: ['just', 'still', 'Take', 'China', 'kinds', 'With', 'let', 'exciting', 'above', 'three']\n",
      "min weights for ZHO: ['able', 'move', 'having', 'difficult', 'Also', 'an', 'comfortable', 'its', '`', 'with']\n",
      "bias term for ZHO: -7\n",
      "max weights for ARA: ['alot', 'self', 'statment', 'thier', 'depend', 'will', 'customers', 'any', 'addition', 'needs']\n",
      "min weights for ARA: ['statement', 'little', 'lot', 'When', 'purpose', 'knowledge', 'has', 'been', 'possible', 'seems']\n",
      "bias term for ARA: 7\n",
      "max weights for DEU: ['often', 'opinion', 'statement', 'beeing', 'special', '-', 'negative', 'Furthermore', 'flexible', 'on']\n",
      "min weights for DEU: ['we', \"'s\", 'However', ';', 'may', 'person', 'thing', 'i', 'making', 'We']\n",
      "bias term for DEU: -10\n",
      "max weights for FRA: ['Indeed', '...', 'exemple', 'population', 'during', ':', 'instance', 'fact', 'you', 'France']\n",
      "min weights for FRA: ['There', 'above', 'human', 'problems', 'hard', 'traffic', 'aspects', 'there', 'out', 'lives']\n",
      "bias term for FRA: -1\n",
      "max weights for HIN: ['towards', 'then', 'which', 'well', 'particular', 'todays', 'Now', 'according', 'topic', 'dont']\n",
      "min weights for HIN: ['Finally', 'years', 'people', 'instance', 'did', 'reasons', 'jobs', 'when', 'probably', 'others']\n",
      "bias term for HIN: -1\n",
      "max weights for ITA: [':', 'think', 'possibility', 'organize', 'Infact', 'probably', 'fact', 'way', 'useful', 'important']\n",
      "min weights for ITA: ['get', 'As', 'First', 'over', 'People', 'There', 'may', 'Also', 'Even', 'Many']\n",
      "bias term for ITA: -2\n",
      "max weights for JPN: ['Japan', 'If', 'Japanese', 'Therefore', 'However', 'First', 'There', 'each', 'communicate', 'style']\n",
      "min weights for JPN: ['an', 'every', 'last', 'he', 'sum', 'possible', 'People', 'a', 'giving', 'field']\n",
      "bias term for JPN: 9\n",
      "max weights for KOR: ['Korea', 'However', 'various', 'lots', 'study', 'usually', 'Second', 'though', 'comfortable', 'company']\n",
      "min weights for KOR: ['come', 'ask', 'this', 'for', 'maybe', 'hand', 'completely', 'else', 'end', 'become']\n",
      "bias term for KOR: 1\n",
      "max weights for SPA: ['going', 'activities', 'maybe', 'transport', 'enviroment', 'diferent', 'matter', 'goals', 'task', 'hand']\n",
      "min weights for SPA: ['which', 'successful', 'i', 'useful', 'So', 'might', 'from', 'especially', 'often', 'First']\n",
      "bias term for SPA: -1\n",
      "max weights for TEL: ['i', 'by', 'may', 'cannot', 'days', 'statement', 'some', 'spending', 'Finally', 'ideas']\n",
      "min weights for TEL: ['believe', ';', 'However', 'you', 'just', 'two', 'or', 'Therefore', 'live', ':']\n",
      "bias term for TEL: 5\n",
      "max weights for TUR: ['Turkey', 'Because', 'dont', 'succesful', 'ways', 'being', 'traffic', 'sum', 'chance', 'You']\n",
      "min weights for TUR: ['society', 'often', ',', 'experience', 'Second', 'various', 'cases', 'keep', 'might', 'through']\n",
      "bias term for TUR: 0\n",
      "max weights for ZHO: ['just', 'Take', 'still', 'China', 'kinds', 'let', 'exciting', 'With', 'air', 'energy']\n",
      "min weights for ZHO: ['able', 'Also', 'move', 'difficult', 'sure', '`', 'having', 'its', 'social', 'situations']\n",
      "bias term for ZHO: -7\n",
      "max weights for ARA: ['alot', 'self', 'statment', 'thier', 'depend', 'customers', 'addition', 'fun', 'will', 'transportation']\n",
      "min weights for ARA: ['statement', 'little', 'lot', 'purpose', 'knowledge', 'seems', 'When', 'been', 'possible', 'has']\n",
      "bias term for ARA: 7\n",
      "max weights for DEU: ['often', 'statement', 'opinion', 'beeing', 'special', '-', 'Furthermore', 'out', 'negative', 'flexible']\n",
      "min weights for DEU: ['we', \"'s\", 'However', ';', 'i', 'may', 'person', 'thing', 'making', 'We']\n",
      "bias term for DEU: -10\n",
      "max weights for FRA: ['Indeed', '...', 'exemple', 'population', ':', 'during', 'instance', 'fact', 'evolution', 'France']\n",
      "min weights for FRA: ['There', 'above', 'there', 'human', 'traffic', 'hard', 'problems', 'aspects', 'university', 'among']\n",
      "bias term for FRA: 0\n",
      "max weights for HIN: ['towards', 'then', 'particular', 'which', 'Now', 'well', 'todays', 'u', 'dont', 'taken']\n",
      "min weights for HIN: ['Finally', 'years', 'people', 'when', 'probably', 'instance', 'did', 'reasons', 'jobs', 'study']\n",
      "bias term for HIN: 0\n",
      "max weights for ITA: ['think', ':', 'possibility', 'organize', 'Infact', 'important', 'real', 'probably', 'able', 'useful']\n",
      "min weights for ITA: ['get', 'First', 'As', 'may', 'over', 'People', 'Also', 'Many', 'There', 'getting']\n",
      "bias term for ITA: -1\n",
      "max weights for JPN: ['Japan', 'If', 'Japanese', 'Therefore', 'There', 'each', 'First', 'However', 'however', 'communicate']\n",
      "min weights for JPN: ['last', 'every', 'an', 'sum', 'he', 'a', 'giving', 'People', 'possible', 'just']\n",
      "bias term for JPN: 9\n",
      "max weights for KOR: ['Korea', 'However', 'various', 'study', 'lots', 'usually', 'company', 'comfortable', 'Second', 'just']\n",
      "min weights for KOR: ['come', 'hand', 'ask', 'for', 'maybe', 'how', 'completely', 'end', 'advantages', 'else']\n",
      "bias term for KOR: 0\n",
      "max weights for SPA: ['activities', 'going', 'enviroment', 'transport', 'maybe', 'goals', 'diferent', 'hand', 'lifes', 'task']\n",
      "min weights for SPA: ['which', 'successful', 'i', 'from', 'useful', 'So', 'might', 'especially', 'question', 'often']\n",
      "bias term for SPA: -2\n",
      "max weights for TEL: ['i', 'may', 'cannot', 'by', 'statement', 'days', 'Finally', 'spending', 'above', 'conclude']\n",
      "min weights for TEL: ['believe', ';', 'However', 'you', 'Therefore', 'just', 'two', 'or', ':', 'live']\n",
      "bias term for TEL: 4\n",
      "max weights for TUR: ['Turkey', 'Because', 'succesful', 'create', 'dont', 'being', 'sum', 'ways', 'ages', 'chance']\n",
      "min weights for TUR: ['society', 'often', 'experience', ',', 'keep', 'Second', 'study', 'various', 'cases', 'might']\n",
      "bias term for TUR: 0\n",
      "max weights for ZHO: ['just', 'still', 'Take', 'China', 'kinds', 'let', 'three', 'exciting', 'told', '?']\n",
      "min weights for ZHO: ['able', 'Also', 'move', 'social', '`', 'with', 'explain', 'comfortable', 'its', 'difficult']\n",
      "bias term for ZHO: -7\n",
      "max weights for ARA: ['alot', 'statment', 'self', 'thier', 'depend', 'customers', 'addition', 'fun', 'he', '!']\n",
      "min weights for ARA: ['statement', 'little', 'lot', 'possible', 'been', 'purpose', 'seems', 'When', 'society', 'lifes']\n",
      "bias term for ARA: 8\n",
      "max weights for DEU: ['often', 'statement', 'opinion', 'beeing', 'special', '-', 'Furthermore', 'negative', 'But', 'out']\n",
      "min weights for DEU: ['we', \"'s\", 'However', ';', 'thing', 'i', 'may', 'making', 'We', 'person']\n",
      "bias term for DEU: -10\n",
      "max weights for FRA: ['Indeed', '...', 'exemple', 'population', ':', 'conclude', 'fact', 'during', 'instance', 'evolution']\n",
      "min weights for FRA: ['there', 'There', 'above', 'human', 'traffic', 'lives', 'hard', 'aspects', 'university', 'among']\n",
      "bias term for FRA: -1\n",
      "max weights for HIN: ['towards', 'then', 'particular', 'Now', 'which', 'todays', 'well', 'taken', 'India', 'dont']\n",
      "min weights for HIN: ['Finally', 'people', 'years', 'did', 'others', 'instance', 'reasons', 'jobs', 'study', 'when']\n",
      "bias term for HIN: 0\n",
      "max weights for ITA: [':', 'think', 'possibility', 'organize', 'fact', 'Infact', 'able', 'way', 'general', 'probably']\n",
      "min weights for ITA: ['get', 'First', 'may', 'over', 'There', 'As', 'Also', 'People', 'Many', 'getting']\n",
      "bias term for ITA: -2\n",
      "max weights for JPN: ['Japan', 'If', 'Japanese', 'Therefore', 'First', 'each', 'disagree', 'However', 'however', 'There']\n",
      "min weights for JPN: ['last', 'every', 'an', 'sum', 'he', 'a', 'giving', 'People', 'am', 'possible']\n",
      "bias term for JPN: 10\n",
      "max weights for KOR: ['Korea', 'However', 'lots', 'study', 'various', 'company', 'usually', 'comfortable', 'just', 'Second']\n",
      "min weights for KOR: ['come', 'maybe', 'hand', 'ask', 'for', 'this', 'how', 'end', 'completely', 'advantages']\n",
      "bias term for KOR: 0\n",
      "max weights for SPA: ['activities', 'going', 'maybe', 'transport', 'goals', 'enviroment', 'diferent', 'hand', 'lifes', 'task']\n",
      "min weights for SPA: ['which', 'successful', 'from', 'i', 'So', 'useful', 'especially', 'might', 'often', 'First']\n",
      "bias term for SPA: -2\n",
      "max weights for TEL: ['i', 'cannot', 'may', 'by', 'statement', 'days', 'Finally', 'spending', 'some', 'he']\n",
      "min weights for TEL: ['believe', ';', 'However', 'you', 'just', 'two', 'Therefore', 'or', ':', 'live']\n",
      "bias term for TEL: 4\n",
      "max weights for TUR: ['Turkey', 'Because', 'dont', 'succesful', 'sum', 'ways', 'being', 'create', 'ages', 'chance']\n",
      "min weights for TUR: ['society', 'often', ',', 'Second', 'experience', 'cases', 'lot', 'study', 'various', 'keep']\n",
      "bias term for TUR: 0\n",
      "max weights for ZHO: ['just', 'still', 'Take', 'China', 'kinds', 'let', 'three', '?', 'exciting', 'told']\n",
      "min weights for ZHO: ['able', 'Also', 'move', 'its', 'difficult', 'social', '`', 'with', 'explain', 'comfortable']\n",
      "bias term for ZHO: -7\n",
      "max weights for ARA: ['alot', 'statment', 'self', 'thier', 'depend', 'customers', 'addition', 'will', 'fun', '!']\n",
      "min weights for ARA: ['statement', 'little', 'lot', 'society', 'possible', 'knowledge', 'something', 'purpose', 'seems', 'lifes']\n",
      "bias term for ARA: 8\n",
      "max weights for DEU: ['often', 'statement', 'opinion', 'beeing', 'But', 'special', '-', 'Furthermore', 'on', 'possible']\n",
      "min weights for DEU: ['we', \"'s\", 'However', ';', 'may', 'person', 'thing', 'i', 'making', 'lots']\n",
      "bias term for DEU: -10\n",
      "max weights for FRA: ['Indeed', '...', 'exemple', 'population', ':', 'instance', 'France', 'conclude', 'during', 'evolution']\n",
      "min weights for FRA: ['There', 'above', 'there', 'human', 'among', 'traffic', 'lives', 'aspects', 'hard', 'problems']\n",
      "bias term for FRA: -2\n",
      "max weights for HIN: ['towards', 'then', 'particular', 'Now', 'well', 'which', 'todays', 'taken', 'making', 'So']\n",
      "min weights for HIN: ['Finally', 'people', 'years', 'reasons', 'did', 'instance', 'nowadays', 'jobs', 'study', 'probably']\n",
      "bias term for HIN: -1\n",
      "max weights for ITA: [':', 'think', 'possibility', 'organize', 'able', 'important', 'Infact', 'way', 'fact', 'probably']\n",
      "min weights for ITA: ['get', 'may', 'First', 'over', 'As', 'Also', 'Many', 'There', 'daily', 'tour']\n",
      "bias term for ITA: -2\n",
      "max weights for JPN: ['Japan', 'If', 'Japanese', 'First', 'Therefore', 'each', 'disagree', 'especially', 'There', 'However']\n",
      "min weights for JPN: ['every', 'an', 'last', 'he', 'sum', 'a', 'giving', 'possible', 'People', 'i']\n",
      "bias term for JPN: 10\n",
      "max weights for KOR: ['Korea', 'However', 'lots', 'various', 'study', 'usually', 'company', 'comfortable', 'Second', 'just']\n",
      "min weights for KOR: ['come', 'hand', 'maybe', 'ask', 'for', 'end', 'completely', 'take', 'advantages', 'this']\n",
      "bias term for KOR: 1\n",
      "max weights for SPA: ['going', 'activities', 'enviroment', 'transport', 'matter', 'goals', 'maybe', 'diferent', 'hand', 'lifes']\n",
      "min weights for SPA: ['which', 'i', 'successful', 'from', 'So', 'useful', 'especially', 'might', 'often', 'First']\n",
      "bias term for SPA: -2\n",
      "max weights for TEL: ['i', 'may', 'cannot', 'statement', 'by', 'days', 'spending', 'ideas', 'Finally', 'conclude']\n",
      "min weights for TEL: ['believe', ';', 'you', 'However', 'just', 'Therefore', 'two', ':', 'or', 'live']\n",
      "bias term for TEL: 5\n",
      "max weights for TUR: ['Turkey', 'Because', 'sum', 'succesful', 'create', 'dont', 'ages', 'chance', 'ways', 'being']\n",
      "min weights for TUR: ['society', 'often', 'Second', ',', 'experience', 'various', 'cases', 'study', 'keep', 'might']\n",
      "bias term for TUR: 0\n",
      "max weights for ZHO: ['just', 'Take', 'still', 'China', 'let', 'kinds', 'three', 'air', 'exciting', 'told']\n",
      "min weights for ZHO: ['able', 'move', 'its', 'Also', 'difficult', '`', 'explain', 'comfortable', 'community', 'social']\n",
      "bias term for ZHO: -7\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(MAX_ITERATIONS):\n",
    "    update = 0\n",
    "    train_accuracy = 0\n",
    "    for i in range(len(train_docs)):\n",
    "        label = train_labels[i]\n",
    "        yhat = predict(train_docs[i])\n",
    "        if yhat != label:\n",
    "            for word in train_docs[i]:\n",
    "                weights[label][word] += train_docs[i][word]\n",
    "                weights[yhat][word] -= train_docs[i][word]\n",
    "            train_accuracy -= 1\n",
    "            update += 1\n",
    "    # print(str(iteration) +\",\"+ str(np.divide(len(train_docs)+train_accuracy, len(train_docs))) +\",\" + str(self.test_eval(dev_docs, dev_labels))+\",\"+str(update), file=sys.stderr)\n",
    "    if np.divide(len(train_docs)+train_accuracy, len(train_docs)) == 1.0:\n",
    "        break\n",
    "    for l in CLASSES:\n",
    "        label_weights = weights[l]\n",
    "        print(\"max weights for \" + l + \": \" + str(sorted(label_weights, key=label_weights.get, reverse = True)[:10]))\n",
    "        print(\"min weights for \" + l + \": \" + str(sorted(label_weights, key=label_weights.get)[:10]))\n",
    "        print(\"bias term for \"+ l + \": \" + str(label_weights['bias_term']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38  0  0  1  0  1  2  3  3  1  2]\n",
      " [ 0 25  2  0  0  3  0  1  0  1  2]\n",
      " [ 2  6 36  0  2  1  1  2  2  1  0]\n",
      " [ 2  3  1 20  1  0  2  0 17  1  0]\n",
      " [ 4  1  5  0 36  0  2  2  1  0  2]\n",
      " [ 6  0  0  0  1 35 15  0  0  0  3]\n",
      " [ 1  0  0  0  0  6 44  0  1  0  8]\n",
      " [ 7  1  3  0  3  4  2 29  1  0  2]\n",
      " [ 3  0  0  8  0  0  0  1 50  0  0]\n",
      " [ 9  6  3  0  0  1  4  0  1 27  6]\n",
      " [ 4  1  1  1  0  3  4  0  3  0 52]]\n"
     ]
    }
   ],
   "source": [
    "pred_labels = [predict(d) for d in dev_docs]\n",
    "confusion_matrix = confusion_matrix(dev_labels, pred_labels, labels=CLASSES)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(confusion_matrix[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = sys.argv[1:]\n",
    "    niters = int(args[0])\n",
    "\n",
    "    train_docs, train_labels = load_featurized_docs('train')\n",
    "    print(len(train_docs), 'training docs with',\n",
    "        sum(len(d) for d in train_docs)/len(train_docs), 'percepts on avg', file=sys.stderr)\n",
    "\n",
    "    dev_docs,  dev_labels  = load_featurized_docs('dev')\n",
    "    print(len(dev_docs), 'dev docs with',\n",
    "        sum(len(d) for d in dev_docs)/len(dev_docs), 'percepts on avg', file=sys.stderr)\n",
    "\n",
    "\n",
    "    test_docs,  test_labels  = load_featurized_docs('test')\n",
    "    print(len(test_docs), 'test docs with',\n",
    "        sum(len(d) for d in test_docs)/len(test_docs), 'percepts on avg', file=sys.stderr)\n",
    "\n",
    "    ptron = Perceptron(train_docs, train_labels, MAX_ITERATIONS=niters, dev_docs=dev_docs, dev_labels=dev_labels)\n",
    "    acc = ptron.test_eval(test_docs, test_labels)\n",
    "    print(acc, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5366 training docs with 154.68747670518076 percepts on avg\n",
      "598 dev docs with 154.81939799331104 percepts on avg\n",
      "604 test docs with 153.6341059602649 percepts on avg\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-aba2b56dfbb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     sum(len(d) for d in test_docs)/len(test_docs), 'percepts on avg')\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mptron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_ITERATIONS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mniters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-191f8f2eada9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train_docs, train_labels, MAX_ITERATIONS, dev_docs, dev_labels)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-191f8f2eada9>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, train_docs, train_labels)\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mweight_inter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrain_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "niters = 30\n",
    "train_docs, train_labels = load_featurized_docs('train')\n",
    "\n",
    "print(len(train_docs), 'training docs with',\n",
    "    sum(len(d) for d in train_docs)/len(train_docs), 'percepts on avg')\n",
    "\n",
    "dev_docs,  dev_labels  = load_featurized_docs('dev')\n",
    "print(len(dev_docs), 'dev docs with',\n",
    "    sum(len(d) for d in dev_docs)/len(dev_docs), 'percepts on avg')\n",
    "\n",
    "\n",
    "test_docs,  test_labels  = load_featurized_docs('test')\n",
    "print(len(test_docs), 'test docs with',\n",
    "    sum(len(d) for d in test_docs)/len(test_docs), 'percepts on avg')\n",
    "\n",
    "ptron = Perceptron(train_docs, train_labels, MAX_ITERATIONS=niters, dev_docs=dev_docs, dev_labels=dev_labels)\n",
    "acc = ptron.test_eval(test_docs, test_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-269ad9e66d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ARA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'add'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "weights['ARA']['add']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
